<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Blazers Command Station</title>
  <link href="https://fonts.cdnfonts.com/css/cascadia-code" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js"></script>

<!-- Load Font Awesome from CDN -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">



<link rel="stylesheet" href="./index.css">
</head>
<body>
  <div id="projectContainer">

    <div id="headerContainer">
      <img src="./Blazers-Logo.png" alt="blazers_logo" class="logo" id="logo"/>
      <h2>Sample Image Analysis Station</h2>
    </div>

    <div id="pictureContainer">
        <div id="album">
          <div id="rock-gallery" class="photoBox">
            
          </div>
        </div>

        <div id="singlePickout">
            <header>
                  <span id="toggleText" class="toggle-text">Exploration Mode</span>
                  <label class="switch">
                    <input type="checkbox" id="toggleMode">
                    <span class="slider round"></span>
                  </label>
            </header>
          <img id="display-image" src="" alt="Selected Image" />
          <div id="stream">
            
            <video id="webcam" autoplay></video>
          </div>
          <i id="camera-icon" class="fas fa-camera"></i>
          <div id="depth-display">
            
          </div>
          <div class="selectedImage_box">
            <h3 id="display-name">Selected Image Name</h3>
            <button type="submit" id="analyze-btn">Analyze</button>
          </div>
        </div>

        <canvas id="screenshot-canvas" style="display:none;"></canvas>
    </div>

    <div id="analysisContainer">
      <div id="analysisHeader">
        <h6>ANALYSIS CONSOLE</h6>

        <div id="analysis-content">
      
          <div id="status">
              <span id="status-text">RUNNING ANALYSIS. . .</span>
              <div id="progress-container">
                  <div id="progress-bar"></div>
              </div>
          </div>
          <div id="result-message">IMAGE ANALYSIS COMPLETE!</div>
          <!-- <button id="download-report-btn">Download Report</button> -->

      </div>
      
      </div>

      <div id="analysis-section">
        <div id="properties-container" class="analysis-box">
            <!-- Rock properties will be populated here -->
        </div>
        <div id="life-support-container" class="analysis-box">
            <!-- Life support potential will be populated here -->
        </div>
        <div id="analyst-container" class="analysis-box">
            <input type="text" id="image-name-input" placeholder="Change Image Name">
            <textarea id="comment-input" placeholder="Add comments"></textarea>
            <input type="text" id="analyst-name" placeholder="Analyst Name and Designation">
            <button id="save-analysis-btn">Save Analysis</button>

            
        </div>
    </div>

    </div>

  </div>


<script type="module">
  import { initializeApp } from "https://www.gstatic.com/firebasejs/10.12.4/firebase-app.js";
  import { getAuth, signInWithEmailAndPassword } from "https://www.gstatic.com/firebasejs/10.12.4/firebase-auth.js";
  import { getStorage, ref, getDownloadURL, uploadBytes } from "https://www.gstatic.com/firebasejs/10.12.4/firebase-storage.js";
  import { getDatabase, ref as dbRef, child, get, update, onValue } from "https://www.gstatic.com/firebasejs/10.12.4/firebase-database.js";
  
  const firebaseConfig = {
    apiKey: "AIzaSyA6c_4j2Zw33NdlP2jSbIp0ySHGSmpluQ8",
    authDomain: "blazers-rovers-sample-database.firebaseapp.com",
    projectId: "blazers-rovers-sample-database",
    storageBucket: "blazers-rovers-sample-database.appspot.com",
    messagingSenderId: "464730486363",
    appId: "1:464730486363:web:78ccfde176cea53e21317e"
  };

  // Initialize Firebase
  const app = initializeApp(firebaseConfig);
  const auth = getAuth(app);
  const storage = getStorage(app);
  const database = getDatabase(app);

  const analysisSection = document.getElementById('analysis-section');
  analysisSection.style.display = 'none';

  document.addEventListener('DOMContentLoaded', function () {
      const gallery = document.getElementById('rock-gallery');
      const displayImage = document.getElementById('display-image');
      const displayName = document.getElementById('display-name');
    
      async function loadRockData() {
        const auth = getAuth();
        const email = "lanre.mohammed23@gmail.com";
        const password = "Wilmar.jr7";
    
        try {
            // Sign in the user to authenticate access to the database
            const userCredential = await signInWithEmailAndPassword(auth, email, password);
            console.log("User signed in successfully");
    
            // Reference to the 'Samples' node in your database
            const rockDataRef = dbRef(database, 'Samples');
            
            // Use onValue for real-time updates
            onValue(child(rockDataRef, '/'), (snapshot) => {
                // Check if the snapshot contains data
                if (snapshot.exists()) {
                    const rockData = snapshot.val();
    
                    // Process each child node, ensuring all keys (short and long) are handled
                    const processedData = {};
                    snapshot.forEach((childSnapshot) => {
                        const key = childSnapshot.key;  // This captures the key, regardless of its format
                        const data = childSnapshot.val();
    
                        // Add the data to the processedData object using the key
                        processedData[key] = data;
                    });
    
                    console.log(processedData);
                    displayRockGallery(processedData);  // Pass processed data to display function
                } else {
                    console.error("No data available");
                }
            }, (error) => {
                console.error("Error fetching data in real-time:", error);
            });
        } catch (error) {
            console.error("Error during authentication or fetching rock data:", error);
        }
    }
    
    

      function displayRockGallery(rockData) {
          const gallery = document.getElementById('rock-gallery');

          Object.values(rockData).forEach(imgData => {
              const card = document.createElement('div');
              card.className = 'image-card';

              const img = document.createElement('img');
              img.setAttribute('loading', 'lazy');  // Lazy loading

              const placeholder = 'data:image/svg+xml;base64,...';  // Placeholder base64 encoded string
              img.src = placeholder;  // Set the placeholder image first

              // Fetch the actual image and replace the placeholder
              const imgRef = ref(storage, imgData.image);
              getDownloadURL(imgRef).then((url) => {
                  img.src = url;
              }).catch((error) => {
                  console.error("Error fetching image:", error);
              });

              const name = document.createElement('div');
              name.className = 'image-name';
              name.innerText = imgData.image_name;

              card.addEventListener('click', () => {
                  analysisSection.style.display = 'none';
                  displayImage.src = img.src;
                  displayName.innerText = imgData.image_name;

                  sessionStorage.clear();
                  storeImageInSession(displayImage.src);
              });

              card.appendChild(img);
              card.appendChild(name);

              gallery.appendChild(card);
          });
      }

      loadRockData();
  });

  // Teachable Machine integration
  const URL = "https://teachablemachine.withgoogle.com/models/NzfitzWEF/";
  let model, maxPredictions;

  async function loadModel() {
      const modelURL = URL + "model.json";
      const metadataURL = URL + "metadata.json";
      model = await tmImage.load(modelURL, metadataURL);
      maxPredictions = model.getTotalClasses();
  }

  async function predictImage(image) {
      const imgElement = document.createElement('img');
      imgElement.crossOrigin = 'anonymous';
      imgElement.src = image.src;

      await new Promise(resolve => imgElement.onload = resolve);

      const prediction = await model.predict(imgElement);
      return prediction;
  }

  async function analyzeImage() {
      const displayImage = document.getElementById('display-image');
      const base64Image = await convertImageToBase64(displayImage.src);
      sessionStorage.setItem('imageData', base64Image);

      const predictions = await predictImage(displayImage);

      if (predictions.length > 0) {
          const highestPrediction = predictions.reduce((prev, current) => (prev.probability > current.probability) ? prev : current);
          const imageName = highestPrediction.className.toLowerCase();
          displayAnalysisData(imageName);
          analysisSection.style.display = 'flex';
      }
  }

  async function convertImageToBase64(imageUrl) {
      return new Promise((resolve, reject) => {
          const img = new Image();
          img.crossOrigin = 'anonymous';
          img.onload = () => {
              const canvas = document.createElement('canvas');
              canvas.width = img.width;
              canvas.height = img.height;
              const ctx = canvas.getContext('2d');
              ctx.drawImage(img, 0, 0);
              const base64String = canvas.toDataURL('image/jpeg');
              resolve(base64String);
          };
          img.onerror = reject;
          img.src = imageUrl;
      });
  }

  function storeImageInSession(imageData) {
      try {
          sessionStorage.setItem('selectedImage', imageData);
      } catch (error) {
          console.error("Error storing image in session storage:", error);
      }
  }

  document.getElementById('analyze-btn').addEventListener('click', function () {
      const status = document.getElementById('status');
      const progressBar = document.getElementById('progress-bar');
      const resultMessage = document.getElementById('result-message');
      const statusText = document.getElementById('status-text');

      status.style.display = 'flex';
      resultMessage.style.display = 'none';
      progressBar.style.width = '0%';

      let progress = 0;
      const interval = setInterval(async () => {
          progress += 10;
          progressBar.style.width = progress + '%';

          if (progress >= 100) {
              clearInterval(interval);
              status.style.display = 'none';
              resultMessage.style.display = 'block';


              await analyzeImage();
              analysisSection.style.display = 'flex';

              document.getElementById('save-analysis-btn').addEventListener('click', async () => {
                  const imageNameInput = document.getElementById('image-name-input').value;
                  const commentInput = document.getElementById('comment-input').value;
                  const analystName = document.getElementById('analyst-name').value;

                  if (imageNameInput && commentInput && analystName) {
                      const updateData = {
                          analyst_name: analystName,
                          analyst_comment: commentInput,
                          image_name: imageNameInput
                      };

                      const rockDataRef = dbRef(database, 'Samples');
                      const displayName = document.getElementById('display-name').innerText.toLowerCase();

                      const snapshot = await get(child(rockDataRef, '/'));
                      if (snapshot.exists()) {
                          const rockData = snapshot.val();
                          console.log(rockData);

                          for (const key in rockData) {
                              if (rockData.hasOwnProperty(key)) {
                                  const sample = rockData[key];
                                  if (sample.image_name.toLowerCase() === displayName) {
                                      await update(child(rockDataRef, key), updateData);
                                      alert("Analysis saved successfully!");
                                      generatePDFReport();
                                      analysisSection.style.display = 'none';
                                      break;
                                  }
                              }
                          }
                      } else {
                          console.error("No data available to update with analyst input");
                      }
                  } else {
                      alert("Please fill out all fields in the Analyst section.");
                  }
              });
          }
      }, 1000);
  });


  function displayAnalysisData(imageName) {
    console.log("Searching for data with image name:", imageName.toLowerCase());
    const datasetRef = dbRef(database, 'Dataset'); // Reference to 'Dataset' node in your database
    
    get(datasetRef).then(snapshot => {
        if (snapshot.exists()) {
            const dataset = snapshot.val();
            let sample = null;

            // Iterate through the dataset to find the object with a matching type
            for (const key in dataset) {
                if (dataset.hasOwnProperty(key)) {
                    const subdata = dataset[key];
                    if (subdata.type && subdata.type.toLowerCase() === imageName.toLowerCase()) {
                        sample = subdata;
                        break;
                    }
                }
            }

            if (sample) {
                console.log("Sample found:", sample);

                // Populate the properties container
                const propertiesContainer = document.getElementById('properties-container');
                propertiesContainer.innerHTML = `
                  <h4>ROCK CHARACTERISTICS</h4>
                  <p><strong>Type:</strong> ${sample.type}  |  <strong>Formation Process:</strong> ${sample.formation_process}</p>
                  <p><strong>Description:</strong> ${sample.description}</p>
                  <p><strong>Texture:</strong> ${sample.texture}  |  <strong>Structure:</strong> ${sample.structure}</p>
                  <p><strong>Mineral Composition:</strong> ${sample.mineral_composition.join(", ")}</p>
                `;

                // Populate the life support container
                const lifeSupportContainer = document.getElementById('life-support-container');
                const lifeSupportYesNo = sample.life_support_potential.percentage >= 50 ? 
                  `<span style="color: lightgreen;">Yes</span>` : `<span style="color: red;">No</span>`;
                lifeSupportContainer.innerHTML = `
                  <h4>Habitability Assessment</h4>
                  <p><strong>Signs of Water:</strong> ${sample.signs_of_water ? 'Yes' : 'No'}</p>
                  <p><strong>Potential to support life:</strong> ${lifeSupportYesNo}, with a ${sample.life_support_potential.percentage}% probability</p>
                  <p><strong>Reason:</strong> ${sample.life_support_potential.description}</p>
                `;
            } else {
                console.log("No matching sample found for the selected image.");
                alert("No matching data found for the selected image.");
            }
        } else {
            console.log("No data found in the dataset.");
            alert("No data found in the dataset.");
        }
    }).catch(error => {
        console.error("Error fetching dataset data:", error);
    });
}

  loadModel();

  function generatePDFReport() {
    // Get the data to include in the report
    const analysisImageSrc = document.getElementById('display-image').src;
    const rockCharacteristics = document.getElementById('properties-container').innerText;
    const habitabilityAssessment = document.getElementById('life-support-container').innerText;
    const analystComment = document.getElementById('comment-input').value;
    const analystName = document.getElementById('analyst-name').value;
    const imageNameInput = document.getElementById('image-name-input').value;
    const logoImageSrc = './Blazers-Logo.png'; // Path to your logo

    // Create the HTML structure dynamically
    const reportContainer = document.createElement('div');
    reportContainer.className = 'report-container';

    // Letterhead section
    const letterhead = document.createElement('div');
    letterhead.className = 'letterhead';

    const logoSection = document.createElement('div');
    logoSection.className = 'logo-section';
    const logoImg = document.createElement('img');
    logoImg.src = logoImageSrc;
    logoSection.appendChild(logoImg);

    const textSection = document.createElement('div');
    textSection.className = 'text-section';
    const title = document.createElement('h1');
    title.innerText = 'Mars Rover Image Analysis Report';
    textSection.appendChild(title);

    letterhead.appendChild(logoSection);
    letterhead.appendChild(textSection);

    // Sample Details section
    const reportSection1 = document.createElement('div');
    reportSection1.className = 'report-section';
    const sampleDetailsTitle = document.createElement('h2');
    sampleDetailsTitle.innerText = 'Sample Details';
    const togetherDiv = document.createElement('div');
    togetherDiv.className = 'together';
    const sampleName = document.createElement('p');
    sampleName.innerHTML = `<b>Sample Name: </b> ${imageNameInput}`;
    const dateCaptured = document.createElement('p');
    dateCaptured.className = 'date';
    dateCaptured.innerHTML = `<b>Date Captured: </b><span>${new Date().toLocaleDateString()}</span>`;
    togetherDiv.appendChild(sampleName);
    togetherDiv.appendChild(dateCaptured);

    // Create a placeholder for the sample image
    const sampleImage = document.createElement('img');
    sampleImage.id = imageNameInput; // Assign an ID based on the image name
    const sampleCaption = document.createElement('i');
    sampleCaption.innerText = `Fig.1 ${imageNameInput}_Sample`;

    reportSection1.appendChild(sampleDetailsTitle);
    reportSection1.appendChild(togetherDiv);
    reportSection1.appendChild(sampleImage);
    reportSection1.appendChild(sampleCaption);

    // Analysis Results section
    const reportSection2 = document.createElement('div');
    reportSection2.className = 'report-section';
    const analysisResultsTitle = document.createElement('h2');
    analysisResultsTitle.innerText = 'Analysis Results';
    const rockCharacteristicsP = document.createElement('p');
    rockCharacteristicsP.innerText = rockCharacteristics;
    const habitabilityAssessmentP = document.createElement('p');
    habitabilityAssessmentP.innerText = habitabilityAssessment;

    reportSection2.appendChild(analysisResultsTitle);
    reportSection2.appendChild(rockCharacteristicsP);
    reportSection2.appendChild(habitabilityAssessmentP);

    // Analyst Information section
    const reportSection3 = document.createElement('div');
    reportSection3.className = 'report-section';
    const analystInfoTitle = document.createElement('h2');
    analystInfoTitle.innerText = 'Analyst Information';
    const analystCommentP = document.createElement('p');
    analystCommentP.innerHTML = `<b>Analyst Comment: </b>${analystComment}`;
    const analystNameP = document.createElement('p');
    analystNameP.innerHTML = `<b>Analyst Name: </b>${analystName}`;

    reportSection3.appendChild(analystInfoTitle);
    reportSection3.appendChild(analystCommentP);
    reportSection3.appendChild(analystNameP);

    // Signature line section
    const signatureLine = document.createElement('div');
    signatureLine.className = 'signature-line';
    const signatureTitle = document.createElement('p');
    signatureTitle.innerText = 'Signature:';
    const signatureLineHr = document.createElement('hr');
    signatureLine.appendChild(signatureTitle);
    signatureLine.appendChild(signatureLineHr);

    // Footer section
    const footer = document.createElement('footer');
    footer.innerHTML = 'Gale Crater Research Station, Latitude -5.4, Longitude 137.8, Mars. blazersteam@gmail.com';

    // Append all sections to the report container
    reportContainer.appendChild(letterhead);
    reportContainer.appendChild(reportSection1);
    reportContainer.appendChild(reportSection2);
    reportContainer.appendChild(reportSection3);
    reportContainer.appendChild(signatureLine);
    reportContainer.appendChild(footer);

    // Add the report container to the document body (for rendering)
    document.body.appendChild(reportContainer);

    // Convert the analysis image to Base64 and generate the PDF
    convertToBase64(analysisImageSrc).then(base64Image => {
        sampleImage.src = base64Image; // Set the sample image source

        html2canvas(reportContainer, { scale: 2 }).then(canvas => {
            const { jsPDF } = window.jspdf;
            const pdf = new jsPDF('p', 'mm', 'a4');

            const imgWidth = 210; // A4 width in mm
            const pageHeight = 295; // A4 height in mm
            const imgHeight = canvas.height * imgWidth / canvas.width;
            const heightLeft = imgHeight - pageHeight;

            let position = 0;

            pdf.addImage(canvas.toDataURL('image/jpeg'), 'JPEG', 0, position, imgWidth, imgHeight);

            if (heightLeft > 0) {
                pdf.addPage();
                pdf.addImage(canvas.toDataURL('image/jpeg'), 'JPEG', 0, -pageHeight, imgWidth, imgHeight);
            }

            pdf.save(`${imageNameInput}_Image_Analysis_Report.pdf`);

            // Clean up the dynamically created content
            document.body.removeChild(reportContainer);
        }).catch(error => {
            console.error("Error generating PDF:", error);
        });
    }).catch(error => {
        console.error("Error converting image to Base64:", error);
    });
}

// Helper function to convert image URL to Base64
function convertToBase64(url) {
    return new Promise((resolve, reject) => {
        const img = new Image();
        img.crossOrigin = 'Anonymous'; // To avoid CORS issues
        img.src = url;
        img.onload = () => {
            const canvas = document.createElement('canvas');
            canvas.width = img.width;
            canvas.height = img.height;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(img, 0, 0);
            const dataURL = canvas.toDataURL('image/jpeg');
            resolve(dataURL);
        };
        img.onerror = error => reject(error);
    });
}

  loadModel();

  document.addEventListener("DOMContentLoaded", function() {
    const video = document.getElementById('webcam');
    const canvas = document.getElementById('screenshot-canvas');  // New canvas for drawing rectangles
    const cameraIcon = document.getElementById('camera-icon');
    const depthDisplay = document.getElementById('depth-display');
    const toggleMode = document.getElementById('toggleMode');
    const toggleText = document.getElementById('toggleText');
    const imageBox = document.querySelector('.selectedImage_box');
    const stream = document.getElementById('stream');
    const imageDisplay = document.getElementById('display-image');
    const URL = "https://teachablemachine.withgoogle.com/models/cPkoUO3KA/"; // Teachable Machine model URL

    let model, maxPredictions;

    // Function to switch to Exploration Mode
    function switchToExplorationMode() {
        toggleText.innerText = "Exploration Mode";  // Update the label text
        depthDisplay.style.display = "flex";
        cameraIcon.style.display = "flex";
        video.style.display = "flex";
        stream.style.display = "flex";
        imageBox.style.display = "none";
        imageDisplay.style.display = "none";
         // Show detection canvas
    }

    // Function to switch to Analysis Mode
    function switchToAnalysisMode() {
        toggleText.innerText = "Analysis Mode";  // Update the label text
        depthDisplay.style.display = "none";
        cameraIcon.style.display = "none";
        video.style.display = "none";
        stream.style.display = "none";
        imageBox.style.display = "flex";
        imageDisplay.style.display = "flex";
         // Hide detection canvas
    }

    // Event listener for the checkbox
    toggleMode.addEventListener('change', function() {
        if (toggleMode.checked) {
            switchToExplorationMode();
        } else {
            switchToAnalysisMode();
        }
    });

    // Initialize the page in Analysis Mode (since the checkbox is unchecked by default)
    switchToAnalysisMode();  // By default, start in Analysis Mode

    // ********** 1. Webcam Stream Functionality ********** //
    function startWebcam() {
        const video = document.getElementById('webcam'); // Assumes a <video> element with id="webcam"
        const canvas = document.getElementById('detection-canvas'); // Assumes a <canvas> element with id="detection-canvas"
        const esp32CamIP = "<ESP32_CAM_IP>"; // Replace with your ESP32-CAM IP address
    
        function startESP32CamStream() {
            return new Promise((resolve, reject) => {
                const cameraSocket = new WebSocket("ws://192.168.4.1/stream");
                
                cameraSocket.binaryType = "blob";
                
                cameraSocket.onmessage = function(event) {
                    
                    video.src = URL.createObjectURL(event.data);
                    video.play();  // Display frame
                };
               
                cameraSocket.onclose = function() {
                    console.log("WebSocket connection closed");
                };
        
                cameraSocket.onerror = function(error) {
                    console.error("WebSocket error: ", error);
                };

                // If the ESP32-CAM stream loads, resolve the promise
                video.addEventListener('loadeddata', () => resolve(true), { once: true });
    
                // Timeout to reject the promise if ESP32-CAM feed isn't available within 5 seconds
                setTimeout(() => reject(false), 5000); // Adjust timeout as needed
            });
        }
    
        async function startFallbackWebcam() {
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    video.srcObject = stream;
                    video.addEventListener('loadedmetadata', function() {
                        console.log('Webcam metadata loaded');
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                    });
                } catch (error) {
                    console.error('Error accessing webcam:', error);
                }
            } else {
                alert('Webcam not supported by your browser.');
            }
        }
    
        // Try to start ESP32-CAM stream, fallback to webcam if unavailable
        startESP32CamStream()
            .then(() => console.log("ESP32-CAM stream started."))
            .catch(() => {
                console.warn("ESP32-CAM stream unavailable, switching to laptop webcam.");
                startFallbackWebcam();
            });
    }
    

    // ********** 2. Teachable Machine Model Integration ********** //
    async function initTeachableMachineModel() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        window.requestAnimationFrame(predictLoop);
    }

    async function predictLoop() {
        await predict();
        window.requestAnimationFrame(predictLoop);
    }

    async function predict() {
        const prediction = await model.predict(video);
        let objectDetected = false;
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction = `${prediction[i].className}: ${prediction[i].probability.toFixed(2)}`;
    
            // Check for specific objects
            if (prediction[i].probability > 0.8) {
                objectDetected = true;
                const detectedObject = prediction[i].className;
                const depth = await sendScreenshotToPython(detectedObject);  // Simulating depth response
                //takeScreenshot(detectedObject, depth);
                //console.log("Object Detected, Take Screenshot");
                //drawRectangleOnVideo(detectedObject);  // Draw the rectangle
                updateDisplay(detectedObject, depth);
            }
        }
        // Change the camera icon to red if an object is detected
        if (objectDetected) {
            cameraIcon.style.color = "red";
        } else {
            cameraIcon.style.color = "white";
            depthDisplay.innerText = "";
              // Reset to default color when no object is detected
        }
    }

    // ********** 3. Screenshot Functionality ********** //
    async function takeScreenshot(objectDetected = "Manual", depth = 1.5) {
        const canvas = document.createElement('canvas');
        const context = canvas.getContext('2d');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        canvas.toBlob(async (blob) => {
            if (blob) {
                console.log("Screenshot taken");
                 // Create a storage reference
                 const timestamp = Date.now();
                 const storageRef = ref(storage, `TEST_SAMPLES/screenshot_${timestamp}.png`);
 
                 // Upload the blob to Firebase Storage
                 await uploadBytes(storageRef, blob);
 
                 // Get the download URL
                 const downloadURL = await getDownloadURL(storageRef);
 
                // Send the blob to the Python service for depth estimation
                await updateDatabaseWithImage(downloadURL, depth, objectDetected);
            } else {
                console.error('Failed to convert canvas to Blob.');
            }
        }, 'image/png');
    }

    // ********** 4. Display Update Function ********** //
    function updateDisplay(material, depth) {
        // Update the 'depthDisplay' paragraph and the 'objectResult' div
        depthDisplay.innerText = `Detected Material: ${material}, Estimated Depth: ${depth.toFixed(2)} meters`;
    }

    // ********** 5. Drawing Rectangle Around Detected Object ********** //
    function drawRectangleOnVideo(detectedObject) {
        canvas.style.display = 'block';
        const ctx = canvas.getContext('2d');
        const width = video.videoWidth;
        const height = video.videoHeight;

        // Clear previous drawings
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Draw a green rectangle in the center of the video (adjust if object detection provides coordinates)
        const rectWidth = width / 4;
        const rectHeight = height / 4;
        const rectX = (width - rectWidth) / 2;
        const rectY = (height - rectHeight) / 2;

        ctx.strokeStyle = 'green';
        ctx.lineWidth = 5;
        ctx.strokeRect(rectX, rectY, rectWidth, rectHeight);

        // Optionally, display detected object text
        ctx.fillStyle = 'green';
        ctx.font = '20px Arial';
        ctx.fillText(detectedObject, rectX, rectY - 10);
    }

    // ********** 6. Backend Communication and Database Updates ********** //
    async function sendScreenshotToPython(objectDetected) {
        // Simulated depth value, replace with backend call if necessary
        const depth = (Math.random() * (2 - 0.2) + 0.2).toFixed(2);
        return parseFloat(depth);  // Return the depth as a number // Placeholder for depth, call Python backend here
    }

    async function updateDatabaseWithImage(blob, depth, objectDetected) {
        const userCredential = await signInWithEmailAndPassword(auth, 'lanre.mohammed23@gmail.com', 'Wilmar.jr7');
        
        // Reference to the database where you want to store the image URL
        const videoImageRef = dbRef(database, 'Samples/');

        // Assuming you want to push a new entry to the 'Samples' node
        await update(child(videoImageRef, Date.now().toString()), {
            object: objectDetected,
            image_name: `screenshot_${Date.now()}`,
            image: blob,
            timestamp: Date.now(),
            depth: depth,// Optional: add a timestamp or any other data you need
        });

         // Alert after successful upload
         alert("Upload to Firebase completed!");
        
        console.log('Database updated with image, depth, and material.');
    }

    // ********** 7. Event Listeners ********** //
    startWebcam();
    initTeachableMachineModel();

    cameraIcon.addEventListener('click', () => takeScreenshot("Manual"));
});


</script>

</body>
</html>